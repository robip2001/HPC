{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tH-3TJfWH0J",
        "outputId": "c5a7625c-258b-4903-b0e8-0cebbb71ea87"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "\n",
        "\n",
        "\n",
        "code = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define N 1024\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "__global__ void matrixMul(int *a, int *b, int *c, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        sum += a[row * width + i] * b[i * width + col];\n",
        "    }\n",
        "    c[row * width + col] = sum;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int *a, *b, *c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    a = (int*)malloc(size);\n",
        "    b = (int*)malloc(size);\n",
        "    c = (int*)malloc(size);\n",
        "\n",
        "    // Initialize matrices\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            a[i * N + j] = i + j;\n",
        "            b[i * N + j] = i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate memory on device\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_c, size);\n",
        "\n",
        "    // Copy data from host to device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel with 2D grid and 2D block\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x, (N + dimBlock.y - 1) / dimBlock.y);\n",
        "    matrixMul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print first and last elements of result\n",
        "    printf(\"c[0][0] = %d, c[%d][%d] = %d\", c[0], N-1, N-1, c[(N-1) * N + (N-1)]);\n",
        "\n",
        "    // Free memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text_file = open(\"assign4b.cu\",\"w\")\n",
        "text_file.write(code)\n",
        "text_file.close()\n",
        "\n",
        "\n",
        "\n",
        "!nvcc assign4b.cu\n",
        "\n",
        "\n",
        "\n",
        "!./a.out\n",
        "\n",
        "\n",
        "\n",
        "!nvprof ./a.out"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
